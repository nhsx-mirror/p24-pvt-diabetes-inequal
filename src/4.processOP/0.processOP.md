---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.14.1
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```python
import os
import glob
#import osmnx as ox
import numpy as np
import pandas as pd
#import networkx as nx
import seaborn as sns
```

```python
# Data path not stored in git repo
path2Data = '../../data'
```

```python
os.makedirs('data/', exist_ok=True)
```

```python
drop = ([
    'OPA ID', 'System Key', 'System Name', 'External ID', 'Count', 
    'Referral ID', 'DOB', 'Date of Death', 'Clinic Code', 
    'Clinic Description', 'Division Code', 'Division Name', 
    'CDG Code', 'CDG Name', 'Consultant', 'Appointment Date/Time', 
    'Booked Date/Time', 'Arrival Date', 'Arrival Date/Time', 
    'Called Date', 'Called Date/Time', 'Seen Date', 'Seen Date/Time',
    'Departure Date', 'Departure Date/Time', 'Consultant_Code_Seen_By',
    'Attendance_Status (Ungrouped) Code', 'Attendance_Status (Ungrouped)',
    'Extended Outcome Code', 'Extended Outcome', 'DNA Reason Code',
    'Cancellation Date', 'Cancellation Date/Time', 'Cancellation By',
    'Cancellation By_Code', 'Clinic Stream Code', 'Clinic Stream'
])

df = []
for file in glob.glob(f'{path2Data}/OP*csv'):
    df.append(
        pd.read_csv(file, encoding='latin1').drop(drop, axis=1)
    )
df = pd.concat(df)
```

```python
names = ({
    'Patient ID'              : 'patientID',
    'Age at Appt'             : 'patientAge',
    'Gender'                  : 'Gender', 
    'Ethnicity'               : 'patientEthnicity',
    'Postcode'                : 'patientPostcode',
    'Days Waited'             : 'daysWaited',
    'Priority_Code'           : 'priorityCode',
    'Priority'                : 'priority',
    'Specialty Code'          : 'specialityCode',
    'Specialty Name'          : 'specialityName',
    'Appointment Date'        : 'appointmentDateTime',
    'Duration'                : 'appointmentDuration',
    'Move Count'              : 'moveCount',
    'First Attendance_Flag'   : 'firstAppointment',
    'Out of Clinic Flag'      : 'outOfClinic',
    'Consultation Media Code' : 'consultationMediaCode',
    'Consultation Media'      : 'consultationMedia',
    'Hospital Site Code'      : 'siteCode',
    'Hospital Site'           : 'site',
    'Appointment Type Code'   : 'appointmentTypeCode',
    'Appointment Type'        : 'appointmentType',
    'Attendance Status Code'  : 'attendanceStatusCode',
    'Attendance Status'       : 'attendanceStatus',
    'Appt Outcome Code'       : 'appointmentOutcomeCode',
    'Appt Outcome'            : 'appointmentOutcome',
    'Cancellation Reason Code': 'cancellationReasonCode',
    'Cancellation Reason'     : 'cancellationReason',
    'DNA Reason'              : 'DNAReason',
    'Diabetes_Flag'           : 'diabetesFlag',
    'Diabetes_Type2_Flag'     : 'diabetesType2Flag'
})
df = df.rename(names, axis=1)
```

```python
df['firstAppointment'] = df['firstAppointment'] == 'Y'
df['daysWaited'] = df['daysWaited'].apply(lambda x: pd.Timedelta (f'{x} days'))
df['appointmentDateTime'] = pd.to_datetime(df['appointmentDateTime'], format='%Y%m%d')
df['appointmentWeekday'] = df['appointmentDateTime'].apply(lambda x: x.strftime('%A'))
df['appointmentDuration'] = df['appointmentDuration'].apply(lambda x: pd.Timedelta (f'{x} min'))
```

```python
df.loc[df['priorityCode'] == 'XXXX', 'priorityCode'] = np.nan
df['priorityCode'] = df['priorityCode'].fillna(99).astype(int)
```

```python
df.loc[df['consultationMediaCode'] == 'XXXX', 'consultationMediaCode'] = np.nan
df['consultationMediaCode'] = df['consultationMediaCode'].fillna(99).astype(int)
```

```python
df.loc[df['cancellationReasonCode'].isin(['Not set', 'NoSet']), 'cancellationReasonCode'] = np.nan
```

```python
df.loc[df['attendanceStatusCode'] == 'XXXX', 'attendanceStatusCode'] = 99
df['attendanceStatusCode'] = df['attendanceStatusCode'].astype(int)
```

```python
def fixPostcode(pc):
    if pd.isna(pc):
        return np.nan
    a = str(pc).upper().split()
    PCout = a[0].strip()
    try:
        PCin = a[1].strip()
    except IndexError:
        return np.nan
    return f'{PCout} {PCin}'

df['patientPostcode'] = df['patientPostcode'].apply(fixPostcode)
```

```python
DNAReasonMap = ({
    'Missing data': 'Unknown',
    'DNA - Patient failed to arrive, reason unknown': 'Unknown',
    'Attended - unable to wait beyond 30 mins': 'UnableToWait',
    'Left Clinic': 'UnableToWait',
    'DNA - Patient died': 'Died',
    'Unknown': 'Unknown',
    'Not specified': 'Unknown',
    'Patient did not arrive-reason not known': 'Unknown',
    'Reason Not Specified': 'Unknown',
    'Patient ill': 'Illness',
    'Patient forgot appointment': 'Forgot',
    'Cancelled too late': 'CancelledTooLate',
    'Patient arrived too late to be seen': 'ArrivedLate',
    'Patient died': 'Died',
    '3': 'Unknown',
    'XXXX': 'Unknown',
    '7': 'Unknown',
    np.nan: np.nan,
    'Coronavirus (COVID-19) patient concern': 'Illness',
    'Coronavirus (COVID-19) confirmed': 'Illness'
})

# Ensure data contains no all ethnicity codes
assert set(df['DNAReason']).issubset(set(DNAReasonMap.keys()))

df['DNAReason'] = df['DNAReason'].map(DNAReasonMap)
df['DNA'] = df['attendanceStatus'] == 'Did Not Attend'
df.loc[~df['DNA'], 'DNAReason'] = np.nan
```

```python
ageBins = [0, 3, 6, 14, 19, 34, 49, 65, 79, np.inf]

df['Age'] = pd.cut(df['patientAge'].astype(float) + 0.001, bins=ageBins)
```

```python
genderToCode = ({
    'Male': '1',
    'Female': '2',
    'Unknown': '99'
})

df.loc[~df['Gender'].isin(genderToCode.keys()), 'Gender'] = 'Unknown'
df['patientGenderCode'] = df['Gender'].map(genderToCode).fillna('99')
```

```python
df.groupby(['patientGenderCode', 'Gender']).size().sort_values(ascending=False)
```

https://www.datadictionary.nhs.uk/data_elements/ethnic_category.html

```python
ethnicityToCode = ({
    'Any Other Ethnic Group': 'S',
    'Any other Black background': 'P',
    'Any other White background': 'C',
    'Any other ethnic group': 'S',
    'Any other mixed background': 'G',
    'Asian - other': 'L',
    'Asian or Asian British - Any other Asian background': 'L',
    'Asian or Asian British - Bangladeshi': 'K',
    'Asian or Asian British - Indian': 'H',
    'Asian or Asian British - Pakistani': 'J',
    'Bangladeshi or British Bangladeshi': 'K',
    'Black African or Black British African': 'N',
    'Black Caribbean or Black British Caribbean': 'M',
    'Black or Black British - African': 'N',
    'Black or Black British - Any other Black background': 'P',
    'Black or Black British - Caribbean': 'M',
    'Chinese': 'R',
    'Indian or British Indian': 'H',
    'Mixed - Any other background': 'G',
    'Mixed - White and Asian': 'F',
    'Mixed - White and Black African': 'E',
    'Mixed - White and Black Caribbean': 'D',
    'Mixed White and Asian': 'F',
    'Mixed White and Black African': 'E',
    'Mixed White and Black Caribbean': 'D',
    'Not Known': '99',
    'Not Set': '99',
    'Not Stated': '99',
    'Not Stated/Refused': 'Z',
    'Other Ethnic Group - Chinese': 'R',
    'Pakistani or British Pakistani': 'J',
    'Unknown': '99',
    'White - Any other White background': 'C',
    'White - British': 'A',
    'White - Irish': 'B',
    'White British': 'A',
    'White Irish': 'B',
    '99': '99'
})

ethnicityFromCode = ({
    'A' : 'White - British',
    'B' : 'White - Irish',
    'C' : 'White - Any other White background',
    'D' : 'Mixed - White and Black Caribbean',
    'E' : 'Mixed - White and Black African',
    'F' : 'Mixed - White and Asian',
    'G' : 'Mixed - Any other mixed background',
    'H' : 'Asian or Asian British - Indian',
    'J' : 'Asian or Asian British - Pakistani',
    'K' : 'Asian or Asian British - Bangladeshi',
    'L' : 'Asian or Asian British - Any other Asian background',
    'M' : 'Black or Black British - Caribbean',
    'N' : 'Black or Black British - African',
    'P' : 'Black or Black British - Any other Black background',
    'R' : 'Other Ethnic Groups - Chinese',
    'S' : 'Other Ethnic Groups - Any other ethnic group',
    'Z' : 'Not-stated',
    '99': 'Unknown'
})
```

```python
df['patientEthnicity'] = df['patientEthnicity'].fillna('99')

# Ensure data contains no all ethnicity codes
assert set(df['patientEthnicity']).issubset(set(ethnicityToCode.keys()))

df['patientEthnicityCode'] = df['patientEthnicity'].map(ethnicityToCode).fillna('99')
df['patientEthnicity'] = df['patientEthnicityCode'].map(ethnicityFromCode).fillna('Unknown')

# Define more general ethnicity groups
df['Ethnicity'] = (
    df['patientEthnicity'].apply(lambda x: x.split()[0])
    .replace({'Not-stated': 'Unknown'})
)
```

```python
df.groupby('Ethnicity').size().sort_values(ascending=False)
```

```python
df['site'] = df['site'].fillna('Unknown')
```

### Associate Patient Postcode with LSOA

```python
lookup = pd.read_pickle('../0.getLSOAlookup/data/PC_OA_MSOA_WD_LAD-lookup.pkl')[['PCout', 'PCin', 'LSOA11CD']]
lookup['postcode'] = lookup['PCout'] + ' ' + lookup['PCin']
```

```python
df = (
    pd.merge(
        df, lookup, 
        left_on='patientPostcode', 
        right_on='postcode', how='left')
    .drop(['PCout', 'PCin', 'postcode'], axis=1)
)
```

### Associated LSOA with IMD

```python
imd = pd.read_pickle('../1.getDeprivationIndices/data/LSOA11-IoD.pkl')['IMD']
```

```python
df = pd.merge(df, imd, left_on='LSOA11CD', right_index=True, how='left')
df['IMD (quintile)'] = pd.qcut(df['IMD'], 5, labels=[1,2,3,4,5], precision=2)
```

### Check Site Codes
Anomalous site code 8FF91 linked with mainly Ipswich postodes - is this Ipswich hospital miscoded?

#### Temporary Fix
Replace 8FF91 with Ipswich Hospital (RDE03)

```python
df.loc[df['siteCode'] == '8FF91', 'patientPostcode'].apply(lambda x: str(x)[:2]).value_counts()
```

```python
df.loc[df['site'] == 'MCCARTHY JANE (PSYCHOLOGIST)', 'site'] = 'Ipswich Hospital'
df.loc[df['siteCode'] == '8FF91', 'siteCode'] = 'RDE03'
```

### Retrieve Lat/Long of Postcodes

```python
cols = ['PCout', 'PCin', 'Lat', 'Long']
allPostcodes = (
    pd.read_pickle('../0.getPostcodeLatLong/data/postcodes.pkl')[cols]
)
allPostcodes['postcode'] = allPostcodes['PCout']  + ' ' + allPostcodes['PCin']
allPostcodes = allPostcodes.drop(['PCout', 'PCin'], axis=1)
```

### Map Site Names to Postcode

```python
site2Postcode = ({
    'Colchester Hospital': 'CO4 5JL',
    'Clacton Hospital': 'CO15 1LH',
    'Halstead Hospital': 'CO9 2DL',
    'Primary Care Centre': 'CO4 5JR',
    'Harwich Hospital': 'CO12 4EX',
    'Essex County Hospital': 'CO12 4EX',
    'The Oaks Hospital': 'CO4 5XR',
    'Hawthorn Avenue Surgery': 'CO4 3GW',
    'MCCARTHY JANE (PSYCHOLOGIST)': 'NE3 1DX',
    'EARLY PSYCHOSIS NMP': 'WV1 2ND',
    'Ipswich Hospital': 'IP4 5PD'
})
df['sitePostcode'] = df['site'].map(site2Postcode).fillna('')
```

```python
sitePostcodes = df['sitePostcode'].apply(lambda x: x.upper()).drop_duplicates().to_frame()
sitePostcodes = (
    pd.merge(sitePostcodes, allPostcodes, 
             left_on='sitePostcode', right_on='postcode', how='left')
    .rename({'Lat': 'siteLatitude', 'Long': 'siteLongitude'}, axis=1)
)
```

```python
df = (
    pd.merge(
        df, sitePostcodes, 
        left_on='sitePostcode', right_on='sitePostcode', how='left')
    .drop(['postcode'], axis=1)
)
```

#### Patient GPS

```python
postcodes = df['patientPostcode'].drop_duplicates().to_frame().dropna()
postcodes = (
    pd.merge(
        postcodes, allPostcodes, 
        left_on='patientPostcode', right_on='postcode', how='left')
    .rename({'Lat': 'patientLatitude', 'Long': 'patientLongitude'}, axis=1)
)
```

```python
df = (
    pd.merge(df, postcodes, 
             left_on='patientPostcode', 
             right_on='patientPostcode', how='left')
    .drop(['postcode'], axis=1)
)
```

#### Remove non Ipswich, Colchester postcodes

```python
df = df.loc[df['patientPostcode'].apply(lambda x: str(x).startswith(('IP', 'CO')))]
df = df.loc[df['sitePostcode'].apply(lambda x: str(x).startswith(('IP', 'CO')))]

# Save rows with incomplete location data seperately - remerge later
missingLoc = df.loc[
      df['patientLongitude'].isna() 
    | df['patientLatitude'].isna()
    | df['siteLatitude'].isna()
    | df['siteLongitude'].isna()
].copy()

# Remove rows with incomplete location data
df = df.loc[
      df['patientLongitude'].notna() 
    & df['patientLatitude'].notna()
    & df['siteLatitude'].notna()
    & df['siteLongitude'].notna()
]
```

### Compute distance between

```python
# Define bounding box from postcode range
minLat, maxLat = df[['patientLatitude', 'siteLatitude']].melt()['value'].agg(['min', 'max']).values
minLong, maxLong = df[['patientLongitude', 'siteLongitude']].melt()['value'].agg(['min', 'max']).values

longBuffer = 1 / 55.6 # 1 mile in longitude degrees
latBuffer = 1 / 66 # 1 mile in latitude degrees

# Add buffer
minLat -= latBuffer
maxLat += latBuffer
minLong -= longBuffer
maxLong += longBuffer
```

##### Download from: https://download.geofabrik.de/europe/great-britain/england.html

```python
# Extract region by bbox
! osmium extract --overwrite --bbox $minLong,$minLat,$maxLong,$maxLat ../0.getOSMmap/england-latest.osm.pbf -o esneft.osm 

# Filter for roads only
! osmium tags-filter --overwrite -o esngeft-highways.osm esneft.osm nw/highway
```

```python
G = ox.graph.graph_from_xml('esngeft-highways.osm', simplify=True)
```

```python
df['patientNode'] = ox.distance.nearest_nodes(G, df['patientLongitude'], df['patientLatitude'])
```

```python
df['siteNode'] = ox.distance.nearest_nodes(G, df['siteLongitude'], df['siteLatitude'])
```

```python
patient2site = df[['patientNode', 'siteNode']].drop_duplicates()
patient2site['patient2site'] = (
    patient2site.apply(
        lambda x: nx.shortest_path_length(
            G, x['patientNode'], x['siteNode'], weight='length', method='dijkstra'), axis=1)
)
```

```python
df = (
    pd.merge(
        df, patient2site, 
        left_on=['patientNode', 'siteNode'], 
        right_on=['patientNode', 'siteNode'], how='left'
    )
)
```

```python
drop = ([
    'siteLatitude', 'siteLongitude', 'patientLatitude', 
    'patientLongitude', 'patientNode', 'siteNode'
])
df = pd.concat([df, missingLoc]).drop_duplicates().reset_index(drop=True).drop(drop, axis=1)
```

### Save processed data

```python
df.to_pickle('data/OPattendance.pkl')
```

### Archived - fix corrupted file


with open('../data/OP 20200101-20200331.csv') as fh:
    columns = fh.readline().strip()

with open('../data/OP 20191001-20191231-new.csv', 'w') as out:
    print(columns, file=out)
    with open('../data/OP 20191001-20191231.csv') as fh:
        for i, line in enumerate(fh):
            a = (line.split('\t'))
            a = a[:-1] + a[-1].split(',')
            for i in range(len(a)):
                a[i] = a[i].strip('"\n')
            for i in range(len(a)):
                if a[i].startswith(' '):
                    a[i-1] = '"' + a[i-1] + ',' + a[i] + '"'
            a = [i for i in a if not i.startswith(' ')]
            a = a[:67]
            print(','.join(a), file=out)
