---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.14.1
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```python
import sys
import json
import sklearn
import numpy as np
import pandas as pd
from pathlib import Path
from pprint import pprint
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from scipy.stats import randint, uniform
from catboost import CatBoostClassifier, Pool
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import FunctionTransformer
from sklearn.model_selection import RandomizedSearchCV
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import roc_curve, roc_auc_score, classification_report

sklearn.set_config(display='diagram')
```

```python
df = pd.read_pickle('data/OPattendance.pkl').drop_duplicates()

# Remove other non-attendance reasons (e.g. provider cancellation)
df = df.loc[df['attendanceStatus'].isin(['Attended', 'Did Not Attend'])]
```

```python
colMap = ({
    'DNA':                   'DNA',
    'siteCode':              'siteCode',
    'priorityCode':          'priorityCode',
    'specialityCode':        'specialityCode',
    'specialityCode':        'specialityCode',
    'firstAppointment':      'firstAppointment',
    'patientAge':            'ageAtAppointment',
    'appointmentWeekday':    'appointmentWeekday',
    'consultationMediaCode': 'consultationMediaCode',
    'patientID':             'patientID',            # Optional
    'appointmentDateTime':   'appointmentDateTime',  # Optional
})

# Train test validation split sizes
train_size = 0.7
test_size = 0.15
val_size = 0.15

# Aggregate categories with few than this number of records
minRecords = 1000

# Global seed for reproducibility
seed = 42

# Output JSON file to store best parameters and report
bestParamsOut = 'bestParams.json'
scoreReportOut = 'classifierReport.json'

# Iterations for CatBoost during hyper-tuning
# Don't set too high (will slow down tuning)
# This is optimised later using early stopping
catboostIterations = 500

# Cross-validated hyper-parameter tuning
cvIterations = 50 # Increase for better tunings
nFolds = 5        # Number of cross-validation folds
nJobs = 1         # Cores - set to -1 to use all available
params = ({
    'estimator__depth':           randint(4, 10),
    'estimator__l2_leaf_reg':     randint(2, 10),
    'estimator__random_strength': uniform.rvs(0, 10, size=100),
})

# Post-tuning early stopping iterations (with eval set)
evalIterations = 10000
earlyStoppingRounds = 10
```

```python
for var in ([
        seed, cvIterations, nFolds, nJobs, evalIterations, 
        earlyStoppingRounds, minRecords
    ]):
    assert isinstance(var, int)

for out in [bestParamsOut, scoreReportOut]:
    assert out.endswith('.json')
    assert Path(out).parent.exists()

assert train_size + test_size + val_size == 1

np.random.seed(seed) # Set global seed
```

```python
# Standardise feature names according to column map
df = df.rename(colMap, axis=1)
```

```python
# Keep only a single entry per patient (most recent)
if {'appointmentDateTime', 'patientID'}.issubset(df.columns):
    df = (
        df.sort_values('appointmentDateTime', ascending=False)
        .groupby('patientID').head(1)
    )
else:
    msg = 'Recommended removing multiple records of same patient.'
    print(msg, file=sys.stderr)
```

```python
def mapTarget(x):
    names = ({
        '1': 'DNA', 'y': 'DNA', 't': 'DNA', 
        'd': 'DNA', '0': 'Attend', 'n': 'Attend', 
        'f': 'Attend', 'a': 'Attend'
    })
    x = str(x).lower().strip()[0]
    return names[x]

df['DNA'] = df['DNA'].apply(mapTarget)
assert set(df['DNA']) == set(['DNA', 'Attend'])
```

```python
class prepareData(BaseEstimator, TransformerMixin):  
    
    def __init__(self, minRecords: int = 1000):
        self._setCatColIdx()
        self.validCats = {}
        self.minRecords = minRecords
    
    def initData(self, X):
        """ Feature engineering required for both fit & transform """
        for col in self.catCols:
            X[col] = X[col].fillna('').apply(lambda x: str(x).lower().strip())
            if col == 'appointmentWeekday':
                X[col] = X[col].apply(lambda x: x[:3])
        return X.copy()
    
    def fit(self, X, y=None):
        X = self.initData(X)
        for col in self.catCols:
            groupSize = X[col].value_counts()
            topGroups = list(groupSize[groupSize >= self.minRecords].index)
            self.validCats[col] = topGroups
        return self
    
    def transform(self, X, y=None):
        X = self.initData(X)
        for col in self.catCols:
            X.loc[~X[col].isin(self.validCats[col]), col] = 'unknown'
        X['consultationMediaCode'] = (
            X['consultationMediaCode'].apply(self._mapUnknown, args=('99',))
        )
        X['firstAppointment'] = self._mapFirstAppointment(X['firstAppointment'])
        return X.loc[:, self.validCols]
    
    def _mapFirstAppointment(self, col):
        col = col.apply(lambda x: str(x).lower().strip()[0])
        names = ({
            '1': 1, 'y': 1, 't': 1,
            '0': 0, 'n': 0, 'f': 0
        })
        col = col.map(names)
        col.loc[~col.isin([0,1])] = np.nan
        return col
            
    def _mapUnknown(self, x, naVal):
        return 'unknown' if x == naVal else x
            
    @property
    def catCols(self):
        return ([
            'siteCode', 'priorityCode', 'consultationMediaCode',
            'specialityCode', 'appointmentWeekday',
        ])
    
    @property
    def notCatCols(self):
        return ([
            'firstAppointment', 'ageAtAppointment'
        ])
    
    @property
    def validCols(self):
        return self.catCols + self.notCatCols   
    
    def _setCatColIdx(self):
        """ Get indices of categoric cols """
        self.catColIdx = []
        for col in self.catCols:
            if col in self.validCols:
                self.catColIdx.append(
                    self.validCols.index(col))
```

```python
prepData = prepareData(minRecords=minRecords)

# Combine all transformations into a ColumnTransformer
transformers = ([
    ('categories', FunctionTransformer(), prepData.catCols),
    ('numeric',    SimpleImputer(missing_values=np.nan, strategy='mean'), prepData.notCatCols),
])
featureTransformer = ColumnTransformer(
    transformers=transformers, remainder='drop')
```

```python
# Define a preProcessor Pipeline encompassing the FeatureEngineering and featureTransformation steps
preProcessor = Pipeline(steps=[
    ('prepare',         prepareData()),
    ('columnTransform', featureTransformer),
])
```

```python
# Combine processor and modelling steps into a Pipeline object
model = Pipeline(steps=[
    ('preprocess',     preProcessor),
    ('estimator',      CatBoostClassifier(
        cat_features=prepData.catColIdx,
        eval_metric='Logloss',
        iterations=catboostIterations, verbose=0, 
        random_seed=np.random.randint(1e9))),
])
```

```python
def train_test_validation_split(
        X, y, train_size=0.8, test_size=0.1, val_size=0.1, seed=None):
    assert train_size + test_size + val_size == 1
    rng = np.random.default_rng(seed)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=(1 - train_size), 
        random_state=rng.integers(1e9))
    
    split2Size = test_size / (test_size + val_size)
    X_val, X_test, y_val, y_test = train_test_split(
        X_test, y_test, test_size=split2Size, 
        random_state=rng.integers(1e9))
    
    return X_train, X_test, X_val, y_train, y_test, y_val
```

```python
X = df.copy()
y = X.pop('DNA')

split = train_test_validation_split(
    X, y, train_size=train_size, test_size=test_size, 
    val_size=val_size, seed=np.random.randint(1e9)
)
X_train, X_test, X_val, y_train, y_test, y_val = map(lambda x: x.copy(), split)
```

```python
# Ensure the train, test and validation sets contain a sample of all categories
tempPrep = prepData.fit(X)
tempVal = prepData.transform(X_val)
tempTest = prepData.transform(X_test)
tempTrain = prepData.transform(X_train)
for catCol in prepData.validCats:
    assert set(tempTest[catCol]) == set(tempTrain[catCol]) == set(tempVal[catCol])
```

```python
cvIterations = 5
gridSearch = RandomizedSearchCV(
    model, params, scoring='neg_log_loss', 
    random_state=np.random.randint(1e9), cv=nFolds, 
    refit=False, n_jobs=nJobs, n_iter=cvIterations, verbose=3)
_ = gridSearch.fit(X_train, y_train)
```

```python
# Extract best parameters from cross-validated randomised search
params = gridSearch.best_params_
params['estimator__iterations'] = evalIterations
_ = model.set_params(**params)
```

```python
# Pre-process the validation set with the tuned model parameters
X_val = model.named_steps['preprocess'].fit(X_train, y_train).transform(X_val)
evalSet = Pool(X_val, y_val, cat_features=prepData.catColIdx)
```

```python
_ = model.fit(
    X_train, y_train, estimator__eval_set=evalSet,
    estimator__early_stopping_rounds=earlyStoppingRounds)
```

```python
# Update iteration parameter to optimal and write to file
bestIteration = model.named_steps['estimator'].get_best_iteration()
params['estimator__iterations'] = bestIteration

with open(bestParamsOut, 'w') as fh:
    json.dump(params, fh)
```

### Tune Decision Threshold

```python
def predict(model, X, threshold=0.5):
    posProb = pd.Series(model.predict_proba(X)[:,1])
    classes = model.classes_
    predictions = (
        posProb.apply(
            lambda x: classes[0] if x < threshold else classes[1])
    )
    return predictions
```

```python
y_trainInt = y_train.apply(lambda x: 1 if x == model.classes_[1] else 0)
y_predPos = model.predict_proba(X_train)[:,1]

fpr, tpr, thresholds = roc_curve(
    y_trainInt, y_predPos, drop_intermediate=False)
AUC = roc_auc_score(y_trainInt, y_predPos)

idx = np.argmin(np.abs(fpr + tpr - 1))
optimalThreshold = thresholds[idx]
```

```python
fig, ax = plt.subplots()
RocCurveDisplay.from_estimator(model, X_train, y_train, ax=ax)
ax.set_xlim([0, 1])
ax.set_ylim([0, 1])
ax.axhline(tpr[idx], xmax=fpr[idx], ls='--', alpha=0.5, c='black')
ax.axvline(fpr[idx], ymax=tpr[idx], ls='--', alpha=0.5, c='black')
ax.scatter(fpr[idx], tpr[idx], c='black')
ax.set_xlabel('False Positive Rate')
ax.set_ylabel('True Positive Rate')
label = f'AUC = {AUC:.2f}, Optimal Threshold = {optimalThreshold:.2f}'
ax.legend(labels=[label], loc='lower right')
fig.savefig('ROCcurve.pdf')
```

```python
importances = pd.Series(
    model.named_steps['estimator'].feature_importances_,
    prepareData().validCols
).sort_values(ascending=False)
importances
```

```python
df['DNAprob'] = pd.DataFrame(model.predict_proba(df), columns=model.classes_)['DNA'].values
df['DNApredict'] = predict(model, df, threshold=optimalThreshold)
```

```python
testPredictions = predict(model, X_test, threshold=optimalThreshold)
report = classification_report(y_test, testPredictions, output_dict=True)
with open(scoreReportOut, 'w') as fh:
    json.dump(report, fh)
```
